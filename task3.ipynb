{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "from scipy.stats import multivariate_normal \n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EM:\n",
    "    def __init__(self, K, mus, sigmas, weights, tol_level, image_path):\n",
    "        self.k = K # number of clusters\n",
    "        self.mus = mus # means k x 1\n",
    "        self.sigmas = sigmas # variances K x1\n",
    "        self. weights = weights # wight of each cluster k x1\n",
    "        self.tol_level = tol_level # the tolarance level\n",
    "        self.data = np.array(Image.open(image_path).convert(\"L\")).reshape(-1,1) #data points  n x 1\n",
    "        # self.data = np.array([[1,1,2,3,4,3,5,7,1,2,3,4]])\n",
    "        # self.data=  np.array(  [[1],\n",
    "        #                         [1],\n",
    "        #                         [2],\n",
    "        #                         [3],\n",
    "        #                         [4],\n",
    "        #                         [3],\n",
    "        #                         [5],\n",
    "        #                         [7],\n",
    "        #                         [1],\n",
    "        #                         [2],\n",
    "        #                         [3],\n",
    "        #                         [4]])\n",
    "        # print(self.data.shape)\n",
    "        self.probabilities = np.array([0])# the probability for each class for each point N X K (2)\n",
    "        \n",
    "\n",
    "    def e_step(self): # prob of each data point for each cluster N X K and the new classes weights\n",
    "        # we need the weights of the classes, parameters of the classes, data point\n",
    "        \n",
    "        temp = np.zeros( (self.data.shape[0], self.k)) # N X K\n",
    "        for i in range(self.k):\n",
    "            pd = scipy.stats.norm(self.mus[i],self.sigmas[i]).pdf(self.data)\n",
    "            temp[:,i] = pd.reshape(-1)\n",
    "        numerator = temp * self.weights.reshape(-1) # numerator done N X K (1)\n",
    "        denominator = numerator.sum(axis=1)[:, np.newaxis]\n",
    "        self.probabilities = numerator / denominator # the probability for each class for each point N X K (2)\n",
    "        self.probabilities[np.isnan(self.probabilities)] = 0\n",
    "        \n",
    "        self.weights = self.probabilities.mean(axis=0).reshape(-1,1)\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "    def m_step(self):\n",
    "        for i in range(self.k):\n",
    "            weight = self.probabilities[:, [i]]\n",
    "            total_weight = weight.sum()\n",
    "            a1 = (self.data * weight).sum(axis=0)\n",
    "            a2 = total_weight\n",
    "            if a1 == 0 or a2 == 0:\n",
    "                self.mus[i] = 0\n",
    "            else:\n",
    "                self.mus[i] = a1 / a2\n",
    "        p1 = np.transpose(np.array([ self.data[:,0] for _ in range(0,self.k)]))\n",
    "        p2 = np.array([ self.mus.reshape(-1) for _ in range(0,self.data.shape[0])]) # n x k\n",
    "        p2 = np.square(p1 - p2)\n",
    "        p2 = p2 * self.probabilities\n",
    "        p2 = np.sum(p2,axis=0).reshape(-1,1)\n",
    "        total_weight = np.sum(self.probabilities, axis=0).reshape(-1,1)\n",
    "        p2 = p2 / total_weight\n",
    "        p2[np.isnan(p2)] = 0\n",
    "        self.sigmas = p2.reshape(-1,1)\n",
    "        \n",
    "    def q_objecive(self,old_mus, old_sigmas,old_weights):\n",
    "        temp = np.zeros( (self.data.shape[0], self.k)) # N X K\n",
    "        for i in range(self.k):\n",
    "            pd = scipy.stats.norm(self.mus[i],self.sigmas[i]).pdf(self.data)\n",
    "            temp[:,i] = pd.reshape(-1)\n",
    "        temp1 = np.log(self.probabilities * temp)\n",
    "        temp1[np.isnan(temp1)] = 0\n",
    "        for i in range(self.k):\n",
    "            pd = scipy.stats.norm(old_mus[i],old_sigmas[i]).pdf(self.data)\n",
    "            temp[:,i] = pd.reshape(-1)\n",
    "        \n",
    "        numerator = temp * old_weights.reshape(-1)\n",
    "        denominator = numerator.sum(axis=1)[:, np.newaxis]\n",
    "        temp = numerator / denominator # the probability for each class for each point N X K (previous) \n",
    "        temp[np.isnan(temp)] = 0\n",
    "        temp = temp * temp1\n",
    "        temp = np.sum(temp, axis=1)\n",
    "        temp = np.sum(temp, axis=0)\n",
    "        if temp < self.tol_level:\n",
    "            return True\n",
    "        # print(temp)\n",
    "        return False\n",
    "        \n",
    "    def cluster(self):\n",
    "        stop = False\n",
    "        self.e_step\n",
    "        self.m_step\n",
    "        itrs = 0\n",
    "        while stop == False:\n",
    "        # for i in range(0,1):\n",
    "            itrs+=1\n",
    "            old_mus = np.array(self.mus)\n",
    "            old_sigs = np.array(self.sigmas)\n",
    "            old_weights = np.array(self.weights)\n",
    "            self.e_step()\n",
    "            self.m_step()\n",
    "            print(itrs)\n",
    "            stop = self.q_objecive(old_mus, old_sigs, old_weights)\n",
    "        return(self.mus, self.sigmas)\n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "k = 4\n",
    "phi = np.full(shape=k, fill_value=1/k) \n",
    "mu = np.array([[25],\n",
    "               [90],\n",
    "               [160],\n",
    "               [240]])\n",
    "sigma = np.array([[1],\n",
    "               [1],\n",
    "               [1],\n",
    "               [1]])\n",
    "e = 0.001\n",
    "\n",
    "em1 = EM(k, mu, sigma, phi, e, r\"dataset3\\testGrayImage.jpg\")\n",
    "# em1.test()\n",
    "results = em1.cluster()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[  0],\n",
      "       [ 85],\n",
      "       [170],\n",
      "       [255]]), array([[0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.]]))\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5d0bf86eb3e3037358ba9c78ec3f827f641a1e9419297de3af080288153d82b8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
